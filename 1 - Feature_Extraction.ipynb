{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### load libraries\n",
    "import os\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "import librosa.display\n",
    "import numpy\n",
    "import json\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check for duplicates\n",
    "First of all check if any of the selected song has the same name, and if so, to avoid problems modify the names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def duplicates(walk_dir):\n",
    "    s = []\n",
    "    for root, subdirs, files in os.walk(walk_dir):\n",
    "        for filename in files:\n",
    "            if \".mp3\" in filename:\n",
    "                file_path = os.path.join(root, filename)\n",
    "                artist = root.split(\"\\\\\")[1]\n",
    "                song = filename.split(\" \",1)[1].split(\".\")[0]\n",
    "                s.append(song)\n",
    "    print(set([x for x in s if s.count(x) > 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicates(\"Dataset\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Count Songs\n",
    "Then we count how many songs we have per artist in the dataset. This requires every file name to be formatted in the same way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count(walk_dir):\n",
    "    x = {}\n",
    "    for root, subdirs, files in os.walk(walk_dir):\n",
    "        for filename in files:\n",
    "            if \".mp3\" in filename:\n",
    "                file_path = os.path.join(root, filename)\n",
    "                artist = root.split(\"\\\\\")[1]\n",
    "                song = filename.split(\" \",1)[1].split(\".\")[0]\n",
    "                if artist not in x:\n",
    "                    x[artist] = 0\n",
    "                x[artist] += 1\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count(\"Dataset\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parse song to extract features for visualization\n",
    "Here we provide the code to extract the MFCC from the song in our database. We extract both normalized *song-by-song* and unnormalized mfcc's. These data will be used for visualization purposes and exploratory analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set parameters:\n",
    "fs = 6000      # sampling rate, default in librosa is 22050\n",
    "offset = 30    # load song with specified offset in sec, to skip noisy intros\n",
    "n_mfcc = 12    # number of mfccs to extract, default is 20, another good value (to reduce dimension) is 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "### define a function to extract the features using the parameters set above\n",
    "scaler = sklearn.preprocessing.StandardScaler() ## to normalize mfcc\n",
    "def create_mfcc_visual(walk_dir):\n",
    "    x = []\n",
    "    x1 = []\n",
    "    for root, subdirs, files in os.walk(walk_dir):\n",
    "        for filename in files:\n",
    "            if \".mp3\" in filename:\n",
    "                file_path = os.path.join(root, filename)\n",
    "                artist = root.split(\"\\\\\")[1]\n",
    "                song = filename.split(\" \",1)[1].split(\".\")[0]\n",
    "                print(\"processing: {}\".format(song))\n",
    "                a = librosa.load(file_path, offset = offset, sr = fs)[0]\n",
    "                mfcc = librosa.feature.mfcc(a, sr = fs, n_mfcc = n_mfcc).T\n",
    "                mfcc_s = scaler.fit_transform(mfcc)\n",
    "                x.append({\"artist\": artist,\"song\": song,\"mfcc\":mfcc_s})\n",
    "                x1.append({\"artist\": artist,\"song\": song,\"mfcc\":mfcc})\n",
    "    return(x,x1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a python list of dictionaries {artist, song, mfcc} using above function\n",
    "# x1 are non-nomalized and will be useful for visualization purposes\n",
    "x, x1 = create_mfcc_visual(\"Dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save files with extracted features\n",
    "\n",
    "##convert mfcc from numpy array to list to be able to place them in a json file\n",
    "y = []\n",
    "for t in x:\n",
    "    y.append({\"artist\": t[\"artist\"],\"song\": t[\"song\"],\"mfcc\":t[\"mfcc\"].tolist()})   \n",
    "\n",
    "y1 = []\n",
    "for t in x1:\n",
    "    y1.append({\"artist\": t[\"artist\"],\"song\": t[\"song\"],\"mfcc\":t[\"mfcc\"].tolist()})\n",
    "\n",
    "# save features\n",
    "with open('visualization-data-norm.txt', 'w') as filehandle:\n",
    "    json.dump(y, filehandle)\n",
    "\n",
    "with open('visualization-data-unnorm.txt', 'w') as filehandle:\n",
    "    json.dump(y1, filehandle)\n",
    "    \n",
    "# save also the sampling rate used to extract features\n",
    "with open('visualization-fs.txt', 'w') as filehandle:\n",
    "    json.dump(fs, filehandle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a variety of datasets with different parameters\n",
    "Here we create different files with features extracted with different parameters to see then how performance of our classifiers change by changing the features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of sampling rates\n",
    "SR = [2500,5000,7500,10000]\n",
    "# list of numbers for mfcc\n",
    "MFCC = [4,8,12,16,20]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to create mfcc with desidered parameters\n",
    "scaler = sklearn.preprocessing.StandardScaler() ## to normalize mfcc\n",
    "def create_multiple_mfcc(walk_dir, SR, MFCC):\n",
    "    x = {}\n",
    "    for sr in SR:\n",
    "        for n_mfcc in MFCC:\n",
    "            x[(sr,n_mfcc)] = []\n",
    "    for root, subdirs, files in os.walk(walk_dir):\n",
    "        for filename in files:\n",
    "            if \".mp3\" in filename:\n",
    "                file_path = os.path.join(root, filename)\n",
    "                artist = root.split(\"\\\\\")[1]\n",
    "                song = filename.split(\" \",1)[1].split(\".\")[0]\n",
    "                for sr in SR:\n",
    "                    a = librosa.load(file_path, offset = offset, sr = sr)[0]\n",
    "                    for n_mfcc in MFCC:\n",
    "                        mfcc = librosa.feature.mfcc(a, sr = sr, n_mfcc = n_mfcc).T\n",
    "                        mfcc = scaler.fit_transform(mfcc)\n",
    "                        x[(sr,n_mfcc)].append({\"artist\": artist,\"song\": song,\"mfcc\":mfcc})\n",
    "    return(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if you want to suppress warnings\n",
    "#import warnings\n",
    "#warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "#use the above function to create features\n",
    "x = create_multiple_mfcc(\"Dataset\",SR,MFCC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# transform x into a dictionary (with elements indexed in SR) of dictionaries (with elements indexed in MFCC)\n",
    "# of list (with elements that represent by songs) of dictionaries of the form {\"artist\", \"song\", \"mfcc\"}\n",
    "# where mfcc has been converted to list to be able to put everything in a json file\n",
    "y = {}\n",
    "for sr in SR:\n",
    "    y[sr] = {}\n",
    "    for n_mfcc in MFCC:\n",
    "        y[sr][n_mfcc]=[]\n",
    "            \n",
    "for key in x:\n",
    "    for t in x[key]:\n",
    "        y[key[0]][key[1]].append({\"artist\": t[\"artist\"],\"song\": t[\"song\"],\"mfcc\":t[\"mfcc\"].tolist()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save features\n",
    "with open('x.txt', 'w') as filehandle:\n",
    "    json.dump(y, filehandle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# also save the list of used SR and MFCC\n",
    "with open('SR.txt', 'w') as filehandle:\n",
    "    json.dump(SR, filehandle)\n",
    "\n",
    "with open('MFCC.txt', 'w') as filehandle:\n",
    "    json.dump(MFCC, filehandle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
