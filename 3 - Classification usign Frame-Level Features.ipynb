{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification usign Frame-Level Features\n",
    "Here we try to classify songs to their respective artist using a two step procedure that consist in classifying frames to artists using standard classifiers (like KNN, SVM ecc.) and then classifying songs to to the artist for which the majority of its frame were classified in the previous step (this is far from the state-of-art but it's something we haven't found online so, though simple, is our own idea)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load libraries\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "import sklearn.discriminant_analysis\n",
    "import librosa.display\n",
    "import numpy\n",
    "import random\n",
    "import pandas\n",
    "import seaborn\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Features\n",
    "After the extraction of the features using the code provided in **Feature_Extraction.ipynb** we can simply load them from the .txt files (this will save time since feature extration can take a while)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('x.txt', 'r') as filehandle:\n",
    "    y = json.load(filehandle)\n",
    "with open('x1.txt', 'r') as filehandle:\n",
    "    y1 = json.load(filehandle)\n",
    "with open('fs.txt', 'r') as filehandle:\n",
    "    fs = json.load(filehandle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "##convert mfccs from list to numpy array that are faster to work with\n",
    "x=[]\n",
    "for t in y:\n",
    "    x.append({\"artist\": t[\"artist\"],\"song\": t[\"song\"],\"mfcc\":numpy.asarray(t[\"mfcc\"])})\n",
    "    \n",
    "x1=[]\n",
    "for t in y1:\n",
    "    x1.append({\"artist\": t[\"artist\"],\"song\": t[\"song\"],\"mfcc\":numpy.asarray(t[\"mfcc\"])})\n",
    "    \n",
    "    \n",
    "    \n",
    "#set n_mfcc by looking at the shape of the feature in the file\n",
    "n_mfcc=x[0][\"mfcc\"].shape[1]\n",
    "#n_mfcc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a Balanced Train-Test split\n",
    "Now we create a random, but balanced, train-test split, meaning that we control randomness ina way to use for training the model the same number of songs per artist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create list of artists\n",
    "artistlist=[]\n",
    "for t in x:\n",
    "    if t[\"artist\"] not in artistlist:\n",
    "        artistlist.append(t[\"artist\"])\n",
    "artistlist.sort()\n",
    "\n",
    "#count number of songs for each artist\n",
    "songcount={}\n",
    "for t in x:\n",
    "    if t[\"artist\"] not in songcount:\n",
    "        songcount[t[\"artist\"]] = 1\n",
    "    else:\n",
    "        songcount[t[\"artist\"]]+=1\n",
    "\n",
    "#find number of songs for the artist having the smallest number of songs\n",
    "artist_with_min = min(songcount.keys(), key=(lambda k: songcount[k]))\n",
    "min_song=songcount[artist_with_min]\n",
    "\n",
    "\n",
    "\n",
    "###create 5-fold or use 3/4 of min_song per each artist as train\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
